# ТЗ: Идея проекта — Local Chat

---

## Концепция

**Local Chat** — это веб-приложение для общения с локальной LLM (Large Language Model), развёрнутой на собственном сервере. По сути, это приватный аналог ChatGPT для небольшой группы пользователей (семья, друзья), без зависимости от внешних API и подписок.

---

## Проблема

Публичные AI-чаты (ChatGPT, Claude) требуют подписки, имеют ограничения по количеству запросов и отправляют данные на внешние серверы. Для пользователей, которые хотят полный контроль над своими данными и неограниченный доступ к AI-ассистенту, нужно локальное решение.

---

## Решение

Веб-интерфейс, который:
- Подключается к локально развёрнутой LLM (Ollama) через n8n workflow
- Предоставляет привычный чат-интерфейс в стиле ChatGPT
- Хранит всю историю диалогов локально
- Работает для небольшой группы авторизованных пользователей

---

## Ключевые особенности

| Функция | Описание |
|---------|----------|
| Чат с LLM | Отправка сообщений, получение ответов, история диалога |
| Многопользовательность | 2-10 пользователей, каждый видит только свои чаты |
| Простая авторизация | Логин/пароль, учётные записи создаёт администратор |
| Markdown-рендеринг | Форматированные ответы с подсветкой кода |
| Управление чатами | Создание, просмотр, удаление диалогов |
| Регенерация ответов | Возможность получить альтернативный ответ |
| Отмена запроса | Прерывание ожидания ответа |

---

## Чего НЕТ в приложении

- Регистрация пользователей (только ручное добавление)
- Загрузка файлов и изображений
- Голосовые сообщения
- Выбор модели (используется одна фиксированная)
- Тёмная тема
- Стриминг ответов (ответ приходит целиком)

---

## Архитектура

```
┌──────────────┐      ┌──────────────┐      ┌──────────────┐
│   Frontend   │ ───▶ │   Backend    │ ───▶ │   n8n        │
│   (React)    │      │   (Node.js)  │      │   Workflow   │
│              │ ◀─── │              │ ◀─── │              │
└──────────────┘      └──────┬───────┘      └──────┬───────┘
                             │                     │
                             ▼                     ▼
                      ┌──────────────┐      ┌──────────────┐
                      │  PostgreSQL  │      │    Ollama    │
                      │  (users,     │      │  (qwen3:30b) │
                      │   chats,     │      │              │
                      │   messages)  │      │              │
                      └──────────────┘      └──────────────┘
```

**Все компоненты работают на одном сервере в Docker-контейнерах.**

---

## Технический стек

| Слой | Технология |
|------|------------|
| Frontend | React, Tailwind CSS, shadcn/ui |
| Backend | Node.js, Express |
| База данных | PostgreSQL |
| LLM-оркестрация | n8n (webhook + AI Agent) |
| LLM | Ollama (модель qwen3:30b) |
| Контейнеризация | Docker, Docker Compose |

---

## Пользовательский сценарий

1. Пользователь открывает сайт → видит форму входа
2. Вводит логин/пароль → попадает на главную страницу
3. Пишет сообщение → создаётся новый чат, отправляется запрос к LLM
4. Получает ответ → может продолжить диалог или начать новый
5. В боковом меню видит все свои чаты → может переключаться между ними
6. В профиле может указать имя/фамилию и выйти из системы

---

## Ограничения

| Ограничение | Причина |
|-------------|---------|
| Один запрос к LLM одновременно | Ограничение Ollama на сервере |
| Таймаут 150 секунд | Долгие ответы LLM |
| Одна активная сессия на пользователя | Простота реализации |
| Нет стриминга | n8n возвращает ответ целиком |

---

## Целевая аудитория

Небольшая группа людей (семья, друзья разработчика), которые хотят пользоваться AI-ассистентом без ограничений и подписок, с полным контролем над данными.

---